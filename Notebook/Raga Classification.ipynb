{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd2f097",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-01T11:26:08.372580Z",
     "iopub.status.busy": "2024-10-01T11:26:08.372247Z",
     "iopub.status.idle": "2024-10-01T11:26:08.377544Z",
     "shell.execute_reply": "2024-10-01T11:26:08.376685Z"
    },
    "papermill": {
     "duration": 0.016342,
     "end_time": "2024-10-01T11:26:08.379571",
     "exception": false,
     "start_time": "2024-10-01T11:26:08.363229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eac2a74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:26:08.394498Z",
     "iopub.status.busy": "2024-10-01T11:26:08.394216Z",
     "iopub.status.idle": "2024-10-01T11:26:09.814893Z",
     "shell.execute_reply": "2024-10-01T11:26:09.813884Z"
    },
    "papermill": {
     "duration": 1.430683,
     "end_time": "2024-10-01T11:26:09.817276",
     "exception": false,
     "start_time": "2024-10-01T11:26:08.386593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import yaml\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee98c5da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:26:09.832540Z",
     "iopub.status.busy": "2024-10-01T11:26:09.832096Z",
     "iopub.status.idle": "2024-10-01T11:26:09.840359Z",
     "shell.execute_reply": "2024-10-01T11:26:09.839458Z"
    },
    "papermill": {
     "duration": 0.018029,
     "end_time": "2024-10-01T11:26:09.842368",
     "exception": false,
     "start_time": "2024-10-01T11:26:09.824339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paths to the audio and annotations\n",
    "audio_path = '/kaggle/input/carnatic-music/carnatic_varnam_1.0/Audio'\n",
    "annotations_path = '/kaggle/input/carnatic-music/carnatic_varnam_1.0/Notations_Annotations/annotations'\n",
    "\n",
    "\n",
    "# List of ragas for classification\n",
    "ragas = ['abhogi', 'begada', 'kalyani', 'mohanam', 'sahana', 'saveri', 'sri']\n",
    "\n",
    "# Function to load audio and extract features (e.g., MFCCs)\n",
    "def extract_features(file_path, n_mfcc=13):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "    return mfccs_mean\n",
    "\n",
    "# Function to parse YAML notations or taala cycle annotations\n",
    "def load_annotations(annotation_file):\n",
    "    with open(annotation_file, 'r') as file:\n",
    "        annotations = yaml.safe_load(file)\n",
    "    return annotations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40430c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:26:09.858022Z",
     "iopub.status.busy": "2024-10-01T11:26:09.857742Z",
     "iopub.status.idle": "2024-10-01T11:26:10.250217Z",
     "shell.execute_reply": "2024-10-01T11:26:10.248885Z"
    },
    "papermill": {
     "duration": 0.401741,
     "end_time": "2024-10-01T11:26:10.251880",
     "exception": true,
     "start_time": "2024-10-01T11:26:09.850139",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/carnatic-music/carnatic_varnam_1.0/Audio/abhogi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m raga_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(audio_path, raga)\n\u001b[1;32m      7\u001b[0m annotation_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(annotations_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtaalas\u001b[39m\u001b[38;5;124m'\u001b[39m, raga)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m audio_file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraga_folder\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m audio_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Assuming audio files are in .wav format\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(raga_folder, audio_file)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/carnatic-music/carnatic_varnam_1.0/Audio/abhogi'"
     ]
    }
   ],
   "source": [
    "# Load all data and annotations\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for raga in ragas:\n",
    "    raga_folder = os.path.join(audio_path, raga)\n",
    "    annotation_folder = os.path.join(annotations_path, 'taalas', raga)\n",
    "    \n",
    "    for audio_file in os.listdir(raga_folder):\n",
    "        if audio_file.endswith('.wav'):  # Assuming audio files are in .wav format\n",
    "            file_path = os.path.join(raga_folder, audio_file)\n",
    "            features = extract_features(file_path)\n",
    "            \n",
    "            # Load corresponding annotation\n",
    "            annotation_file = os.path.join(annotation_folder, audio_file.replace('.wav', '.yaml'))\n",
    "            annotations = load_annotations(annotation_file)\n",
    "            \n",
    "            # Append features and corresponding raga label\n",
    "            X.append(features)\n",
    "            y.append(raga)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d24c3f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a baseline Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f92b3e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=ragas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf9ea88",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import yaml\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Paths to the audio and annotations\n",
    "audio_path = '/path/to/Audio'\n",
    "annotations_path = '/path/to/Notations_Annotations/annotations'\n",
    "\n",
    "# List of ragas for classification\n",
    "ragas = ['abhogi', 'begada', 'kalyani', 'mohanam', 'sahana', 'saveri', 'sri']\n",
    "\n",
    "# Function to load audio and extract features (e.g., MFCCs)\n",
    "def extract_features(file_path, n_mfcc=13):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "    return mfccs_mean\n",
    "\n",
    "# Function to parse YAML notations or taala cycle annotations\n",
    "def load_annotations(annotation_file):\n",
    "    with open(annotation_file, 'r') as file:\n",
    "        annotations = yaml.safe_load(file)\n",
    "    return annotations\n",
    "\n",
    "# Load all data and annotations\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for raga in ragas:\n",
    "    raga_folder = os.path.join(audio_path, raga)\n",
    "    annotation_folder = os.path.join(annotations_path, 'taalas', raga)\n",
    "    \n",
    "    for audio_file in os.listdir(raga_folder):\n",
    "        if audio_file.endswith('.wav'):  # Assuming audio files are in .wav format\n",
    "            file_path = os.path.join(raga_folder, audio_file)\n",
    "            features = extract_features(file_path)\n",
    "            \n",
    "            # Load corresponding annotation\n",
    "            annotation_file = os.path.join(annotation_folder, audio_file.replace('.wav', '.yaml'))\n",
    "            annotations = load_annotations(annotation_file)\n",
    "            \n",
    "            # Append features and corresponding raga label\n",
    "            X.append(features)\n",
    "            y.append(raga)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a baseline Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=ragas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18440467",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcda413c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to dataset folders\n",
    "AUDIO_PATH = \"/path/to/carnatic_varnam_1.0/Audio\"\n",
    "ANNOTATIONS_PATH = \"/path/to/carnatic_varnam_1.0/Notations_Annotations/annotations/taalas\"\n",
    "\n",
    "# Define ragas based on folder structure of annotations\n",
    "ragas = ['abhogi', 'begada', 'kalyani', 'mohanam', 'sahana', 'saveri', 'sri']\n",
    "\n",
    "# Helper function to extract MFCC features from audio\n",
    "def extract_features(audio_file, sr=22050, n_mfcc=13):\n",
    "    y, sr = librosa.load(audio_file, sr=sr)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfcc.T, axis=0)\n",
    "\n",
    "# Function to match audio files with their respective raga based on annotations\n",
    "def match_audio_to_raga():\n",
    "    data = []\n",
    "    for raga in ragas:\n",
    "        annotation_dir = os.path.join(ANNOTATIONS_PATH, raga)\n",
    "        if os.path.isdir(annotation_dir):\n",
    "            for annotation_file in os.listdir(annotation_dir):\n",
    "                if annotation_file.endswith('.yaml'):\n",
    "                    annotation_path = os.path.join(annotation_dir, annotation_file)\n",
    "                    # Parse YAML file to get audio file reference\n",
    "                    with open(annotation_path, 'r') as f:\n",
    "                        annotation_data = yaml.safe_load(f)\n",
    "                        # Loop through the cycles and match to audio files\n",
    "                        for section in annotation_data.values():\n",
    "                            for cycle in section:\n",
    "                                # Assuming audio filenames follow a pattern that matches the annotation\n",
    "                                audio_filename = f\"{cycle}.wav\"\n",
    "                                audio_filepath = os.path.join(AUDIO_PATH, audio_filename)\n",
    "                                if os.path.exists(audio_filepath):\n",
    "                                    # Extract features\n",
    "                                    features = extract_features(audio_filepath)\n",
    "                                    data.append([features, raga])\n",
    "    return data\n",
    "\n",
    "# Preprocess data\n",
    "data = match_audio_to_raga()\n",
    "df = pd.DataFrame(data, columns=['features', 'label'])\n",
    "\n",
    "# Split into features (X) and labels (y)\n",
    "X = np.array(df['features'].tolist())\n",
    "y = df['label']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9500e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T17:54:06.976334Z",
     "iopub.status.busy": "2024-09-26T17:54:06.975620Z",
     "iopub.status.idle": "2024-09-26T17:54:07.365439Z",
     "shell.execute_reply": "2024-09-26T17:54:07.364635Z",
     "shell.execute_reply.started": "2024-09-26T17:54:06.976289Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19117f72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T17:57:19.334239Z",
     "iopub.status.busy": "2024-09-26T17:57:19.333551Z",
     "iopub.status.idle": "2024-09-26T17:57:19.339896Z",
     "shell.execute_reply": "2024-09-26T17:57:19.338974Z",
     "shell.execute_reply.started": "2024-09-26T17:57:19.334197Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to dataset folders\n",
    "AUDIO_PATH = \"/kaggle/input/carnatic-music/carnatic_varnam_1.0/Audio\"\n",
    "ANNOTATIONS_PATH = \"/kaggle/input/carnatic-music/carnatic_varnam_1.0/Notations_Annotations/notations\"\n",
    "\n",
    "# Define ragas based on folder structure of annotations\n",
    "ragas = ['abhogi', 'begada', 'kalyani', 'mohanam', 'sahana', 'saveri', 'sri']\n",
    "\n",
    "# Helper function to extract MFCC features from audio\n",
    "def extract_features(audio_file, sr=22050, n_mfcc=13):\n",
    "    y, sr = librosa.load(audio_file, sr=sr)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfcc.T, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd810e22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T17:58:37.345805Z",
     "iopub.status.busy": "2024-09-26T17:58:37.345427Z",
     "iopub.status.idle": "2024-09-26T17:58:37.354114Z",
     "shell.execute_reply": "2024-09-26T17:58:37.353077Z",
     "shell.execute_reply.started": "2024-09-26T17:58:37.345768Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to match audio files with their respective raga based on annotations\n",
    "def match_audio_to_raga():\n",
    "    data = []\n",
    "    for raga in ragas:\n",
    "        annotation_dir = os.path.join(ANNOTATIONS_PATH, raga)\n",
    "        if os.path.isdir(annotation_dir):\n",
    "            for annotation_file in os.listdir(annotation_dir):\n",
    "                if annotation_file.endswith('.yaml'):\n",
    "                    annotation_path = os.path.join(annotation_dir, annotation_file)\n",
    "                    # Parse YAML file to get audio file reference\n",
    "                    with open(annotation_path, 'r') as f:\n",
    "                        annotation_data = yaml.safe_load(f)\n",
    "                        # Loop through the cycles and match to audio files\n",
    "                        for section in annotation_data.values():\n",
    "                            for cycle in section:\n",
    "                                # Assuming audio filenames follow a pattern that matches the annotation\n",
    "                                audio_filename = f\"{cycle}.wav\"\n",
    "                                audio_filepath = os.path.join(AUDIO_PATH, audio_filename)\n",
    "                                if os.path.exists(audio_filepath):\n",
    "                                    # Extract features\n",
    "                                    features = extract_features(audio_filepath)\n",
    "                                    print(\"Hello\")\n",
    "                                    data.append([features, raga])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f409f46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T17:58:38.909147Z",
     "iopub.status.busy": "2024-09-26T17:58:38.908757Z",
     "iopub.status.idle": "2024-09-26T17:58:38.974461Z",
     "shell.execute_reply": "2024-09-26T17:58:38.973302Z",
     "shell.execute_reply.started": "2024-09-26T17:58:38.909110Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "data = match_audio_to_raga()\n",
    "df = pd.DataFrame(data, columns=['features', 'label'])\n",
    "\n",
    "# Split into features (X) and labels (y)\n",
    "X = np.array(df['features'].tolist())\n",
    "y = df['label']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6607ee4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f30d4b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict and evaluate model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d85591",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e27d09",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to dataset folders\n",
    "AUDIO_PATH = \"/path/to/carnatic_varnam_1.0/Audio\"\n",
    "ANNOTATIONS_PATH = \"/path/to/carnatic_varnam_1.0/Notations_Annotations/annotations/taalas\"\n",
    "\n",
    "# Define ragas based on folder structure of annotations\n",
    "ragas = ['abhogi', 'begada', 'kalyani', 'mohanam', 'sahana', 'saveri', 'sri']\n",
    "\n",
    "# Helper function to extract MFCC features from audio\n",
    "def extract_features(audio_file, sr=22050, n_mfcc=13):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_file, sr=sr)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        return np.mean(mfcc.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {audio_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to match audio files with their respective raga based on annotations\n",
    "def match_audio_to_raga():\n",
    "    data = []\n",
    "    for raga in ragas:\n",
    "        annotation_dir = os.path.join(ANNOTATIONS_PATH, raga)\n",
    "        if os.path.isdir(annotation_dir):\n",
    "            print(f\"Processing raga: {raga}\")\n",
    "            for annotation_file in os.listdir(annotation_dir):\n",
    "                if annotation_file.endswith('.yaml'):\n",
    "                    annotation_path = os.path.join(annotation_dir, annotation_file)\n",
    "                    # Parse YAML file to get audio file reference\n",
    "                    with open(annotation_path, 'r') as f:\n",
    "                        annotation_data = yaml.safe_load(f)\n",
    "                        # Loop through the cycles and match to audio files\n",
    "                        for section in annotation_data.values():\n",
    "                            for cycle in section:\n",
    "                                # Assuming audio filenames follow a pattern that matches the annotation\n",
    "                                audio_filename = f\"{cycle}.wav\"  # Verify this naming assumption\n",
    "                                audio_filepath = os.path.join(AUDIO_PATH, audio_filename)\n",
    "                                if os.path.exists(audio_filepath):\n",
    "                                    print(f\"Matching audio file: {audio_filename} to raga: {raga}\")\n",
    "                                    # Extract features\n",
    "                                    features = extract_features(audio_filepath)\n",
    "                                    if features is not None:\n",
    "                                        data.append([features, raga])\n",
    "                                else:\n",
    "                                    print(f\"Audio file {audio_filename} not found.\")\n",
    "    return data\n",
    "\n",
    "# Preprocess data\n",
    "data = match_audio_to_raga()\n",
    "\n",
    "if len(data) == 0:\n",
    "    print(\"No data found. Please check the audio filenames and annotations.\")\n",
    "else:\n",
    "    df = pd.DataFrame(data, columns=['features', 'label'])\n",
    "\n",
    "    # Split into features (X) and labels (y)\n",
    "    X = np.array(df['features'].tolist())\n",
    "    y = df['label']\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a Random Forest Classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e50c26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T18:02:33.626859Z",
     "iopub.status.busy": "2024-09-26T18:02:33.626453Z",
     "iopub.status.idle": "2024-09-26T18:02:36.576774Z",
     "shell.execute_reply": "2024-09-26T18:02:36.575671Z",
     "shell.execute_reply.started": "2024-09-26T18:02:33.626812Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac29e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T18:03:10.133207Z",
     "iopub.status.busy": "2024-09-26T18:03:10.132571Z",
     "iopub.status.idle": "2024-09-26T18:03:10.141175Z",
     "shell.execute_reply": "2024-09-26T18:03:10.139903Z",
     "shell.execute_reply.started": "2024-09-26T18:03:10.133162Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to dataset folders\n",
    "AUDIO_PATH = \"/kaggle/input/carnatic-music/carnatic_varnam_1.0/Audio\"\n",
    "ANNOTATIONS_PATH = \"/kaggle/input/carnatic-music/carnatic_varnam_1.0/Audio\"\n",
    "\n",
    "# Define ragas based on folder structure of annotations\n",
    "ragas = ['abhogi', 'begada', 'kalyani', 'mohanam', 'sahana', 'saveri', 'sri']\n",
    "\n",
    "# Helper function to extract MFCC features from audio\n",
    "def extract_features(audio_file, sr=22050, n_mfcc=13):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_file, sr=sr)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        return np.mean(mfcc.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {audio_file}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9681df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T18:04:02.328780Z",
     "iopub.status.busy": "2024-09-26T18:04:02.328335Z",
     "iopub.status.idle": "2024-09-26T18:04:02.357102Z",
     "shell.execute_reply": "2024-09-26T18:04:02.355699Z",
     "shell.execute_reply.started": "2024-09-26T18:04:02.328739Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to match audio files with their respective raga based on annotations\n",
    "def match_audio_to_raga():\n",
    "    data = []\n",
    "    for raga in ragas:\n",
    "        annotation_dir = os.path.join(ANNOTATIONS_PATH)\n",
    "        if os.path.isdir(annotation_dir):\n",
    "            print(f\"Processing raga: {raga}\")\n",
    "            for annotation_file in os.listdir(annotation_dir):\n",
    "                if annotation_file.endswith('.yaml'):\n",
    "                    annotation_path = os.path.join(annotation_dir, annotation_file)\n",
    "                    # Parse YAML file to get audio file reference\n",
    "                    with open(annotation_path, 'r') as f:\n",
    "                        annotation_data = yaml.safe_load(f)\n",
    "                        # Loop through the cycles and match to audio files\n",
    "                        for section in annotation_data.values():\n",
    "                            for cycle in section:\n",
    "                                # Assuming audio filenames follow a pattern that matches the annotation\n",
    "                                audio_filename = f\"{cycle}.wav\"  # Verify this naming assumption\n",
    "                                audio_filepath = os.path.join(AUDIO_PATH, audio_filename)\n",
    "                                if os.path.exists(audio_filepath):\n",
    "                                    print(f\"Matching audio file: {audio_filename} to raga: {raga}\")\n",
    "                                    # Extract features\n",
    "                                    features = extract_features(audio_filepath)\n",
    "                                    if features is not None:\n",
    "                                        data.append([features, raga])\n",
    "                                else:\n",
    "                                    print(f\"Audio file {audio_filename} not found.\")\n",
    "    return data\n",
    "\n",
    "# Preprocess data\n",
    "data = match_audio_to_raga()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c949a67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T18:04:07.480128Z",
     "iopub.status.busy": "2024-09-26T18:04:07.479726Z",
     "iopub.status.idle": "2024-09-26T18:04:07.488911Z",
     "shell.execute_reply": "2024-09-26T18:04:07.487777Z",
     "shell.execute_reply.started": "2024-09-26T18:04:07.480092Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(data) == 0:\n",
    "    print(\"No data found. Please check the audio filenames and annotations.\")\n",
    "else:\n",
    "    df = pd.DataFrame(data, columns=['features', 'label'])\n",
    "\n",
    "    # Split into features (X) and labels (y)\n",
    "    X = np.array(df['features'].tolist())\n",
    "    y = df['label']\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a Random Forest Classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a57ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T15:15:55.522969Z",
     "iopub.status.busy": "2024-09-29T15:15:55.522589Z",
     "iopub.status.idle": "2024-09-29T15:15:59.322377Z",
     "shell.execute_reply": "2024-09-29T15:15:59.321440Z",
     "shell.execute_reply.started": "2024-09-29T15:15:55.522930Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to dataset folders\n",
    "AUDIO_PATH = \"/kaggle/input/carnatic-music/carnatic_varnam_1.0/Audio\"\n",
    "ANNOTATIONS_PATH = \"/kaggle/input/carnatic-music/carnatic_varnam_1.0/Notations_Annotations/notations\"\n",
    "\n",
    "# Define ragas based on folder structure of annotations\n",
    "ragas = ['abhogi', 'begada', 'kalyani', 'mohanam', 'sahana', 'saveri', 'sri']\n",
    "\n",
    "# Helper function to extract MFCC features from audio\n",
    "def extract_features(audio_file, sr=22050, n_mfcc=13):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_file, sr=sr)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        return np.mean(mfcc.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {audio_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to match audio files with their respective raga based on annotations\n",
    "def match_audio_to_raga():\n",
    "    data = []\n",
    "    for raga in ragas:\n",
    "#         annotation_dir = os.path.join(ANNOTATIONS_PATH, raga)\n",
    "        annotation_dir = ANNOTATIONS_PATH\n",
    "        if os.path.isdir(annotation_dir):\n",
    "            print(f\"Processing raga: {raga}\")\n",
    "            for annotation_file in os.listdir(annotation_dir):\n",
    "                if annotation_file.endswith('.yaml'):\n",
    "                    annotation_path = os.path.join(annotation_dir, annotation_file)\n",
    "                    # Parse YAML file to get audio file reference\n",
    "                    with open(annotation_path, 'r') as f:\n",
    "                        annotation_data = yaml.safe_load(f)\n",
    "                        # Loop through the cycles and match to audio files\n",
    "                        for section in annotation_data.values():\n",
    "                            for cycle in section:\n",
    "                                # Assuming audio filenames follow a pattern that matches the annotation\n",
    "                                audio_filename = f\"{cycle}.wav\"  # Verify this naming assumption\n",
    "                                audio_filepath = os.path.join(AUDIO_PATH, audio_filename)\n",
    "                                if os.path.exists(audio_filepath):\n",
    "                                    print(f\"Matching audio file: {audio_filename} to raga: {raga}\")\n",
    "                                    # Extract features\n",
    "                                    features = extract_features(audio_filepath)\n",
    "                                    if features is not None:\n",
    "                                        data.append([features, raga])\n",
    "                                else:\n",
    "                                    print(f\"Audio file {audio_filename} not found.\")\n",
    "    return data\n",
    "\n",
    "# Preprocess data\n",
    "data = match_audio_to_raga()\n",
    "\n",
    "if len(data) == 0:\n",
    "    print(\"No data found. Please check the audio filenames and annotations.\")\n",
    "else:\n",
    "    df = pd.DataFrame(data, columns=['features', 'label'])\n",
    "\n",
    "    # Split into features (X) and labels (y)\n",
    "    X = np.array(df['features'].tolist())\n",
    "    y = df['label']\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a Random Forest Classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936fe59b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T15:49:29.316663Z",
     "iopub.status.busy": "2024-09-29T15:49:29.316280Z",
     "iopub.status.idle": "2024-09-29T15:49:29.940724Z",
     "shell.execute_reply": "2024-09-29T15:49:29.939856Z",
     "shell.execute_reply.started": "2024-09-29T15:49:29.316628Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/kaggle/input/dataset-ragas-excel/Dataset.csv')\n",
    "\n",
    "# Separate features and target label\n",
    "X = df.drop(columns=['filename', 'raga'])  # 'filename' is irrelevant for classification, 'raga' is the label\n",
    "y = df['raga']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b95a46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T15:54:01.990731Z",
     "iopub.status.busy": "2024-09-29T15:54:01.990137Z",
     "iopub.status.idle": "2024-09-29T15:54:02.037722Z",
     "shell.execute_reply": "2024-09-29T15:54:02.036823Z",
     "shell.execute_reply.started": "2024-09-29T15:54:01.990689Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/kaggle/input/dataset-ragas-excel/Dataset.csv')\n",
    "\n",
    "# Separate features and target label\n",
    "X = df.drop(columns=['filename', 'raga'])  # 'filename' is irrelevant for classification, 'raga' is the label\n",
    "y = df['raga']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes Classifier\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab7ec3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T15:57:27.212944Z",
     "iopub.status.busy": "2024-09-29T15:57:27.212084Z",
     "iopub.status.idle": "2024-09-29T15:57:27.463380Z",
     "shell.execute_reply": "2024-09-29T15:57:27.462369Z",
     "shell.execute_reply.started": "2024-09-29T15:57:27.212904Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/kaggle/input/dataset-ragas-excel/Dataset.csv')\n",
    "\n",
    "# Separate features and target label\n",
    "X = df.drop(columns=['filename', 'raga'])  # 'filename' is irrelevant for classification, 'raga' is the label\n",
    "y = df['raga']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define different SVM kernels to test\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "\n",
    "# Loop through each kernel, train the model, and evaluate performance\n",
    "for kernel in kernels:\n",
    "    print(f\"\\nSVM with {kernel} kernel:\")\n",
    "    \n",
    "    # Initialize SVM with the current kernel\n",
    "    svm = SVC(kernel=kernel, random_state=42)\n",
    "    \n",
    "    # Train the SVM model\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    # Detailed classification report\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5633251,
     "sourceId": 9303174,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5788585,
     "sourceId": 9509965,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30776,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.17912,
   "end_time": "2024-10-01T11:26:10.678090",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-01T11:26:05.498970",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
